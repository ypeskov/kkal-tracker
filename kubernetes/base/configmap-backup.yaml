apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-script
data:
  backup.sh: |
    #!/bin/bash
    set -e

    # Configuration
    DB_PATH="${DATABASE_PATH:-/data/app.db}"
    BACKUP_DIR="${BACKUP_PATH:-/data/backups}"
    RETENTION_DAYS="${RETENTION_DAYS:-7}"
    GDRIVE_FOLDER_ID="${GDRIVE_FOLDER_ID}"
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    BACKUP_FILE="kkal_tracker_backup_${TIMESTAMP}.db"

    # Create backup directory if it doesn't exist
    mkdir -p "${BACKUP_DIR}"

    # Check if database exists
    if [ ! -f "${DB_PATH}" ]; then
        echo "Error: Database file not found at ${DB_PATH}"
        exit 1
    fi

    echo "Starting backup of database: ${DB_PATH}"
    echo "Backup timestamp: ${TIMESTAMP}"

    # Install required packages
    echo "Installing required packages..."
    apt-get update -qq && apt-get install -qq -y sqlite3 > /dev/null
    pip3 install --quiet google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

    # Create backup using SQLite's backup command (ensures consistency)
    echo "Creating SQLite backup..."
    sqlite3 "${DB_PATH}" ".backup '${BACKUP_DIR}/${BACKUP_FILE}'"

    # Verify backup was created
    if [ ! -f "${BACKUP_DIR}/${BACKUP_FILE}" ]; then
        echo "Error: Backup file was not created"
        exit 1
    fi

    # Get backup size
    BACKUP_SIZE=$(du -h "${BACKUP_DIR}/${BACKUP_FILE}" | cut -f1)
    echo "Backup created successfully: ${BACKUP_FILE} (${BACKUP_SIZE})"

    # Compress backup
    echo "Compressing backup..."
    gzip "${BACKUP_DIR}/${BACKUP_FILE}"
    COMPRESSED_FILE="${BACKUP_FILE}.gz"
    COMPRESSED_SIZE=$(du -h "${BACKUP_DIR}/${COMPRESSED_FILE}" | cut -f1)
    echo "Compressed backup: ${COMPRESSED_FILE} (${COMPRESSED_SIZE})"

    # Upload to Google Drive if credentials are provided
    if [ -n "${GOOGLE_CREDENTIALS_JSON}" ] && [ -n "${GDRIVE_FOLDER_ID}" ]; then
        echo "Uploading to Google Drive..."
        echo "Folder ID: ${GDRIVE_FOLDER_ID}"

        # Save credentials to file
        echo "${GOOGLE_CREDENTIALS_JSON}" > /tmp/credentials.json

        # Use Python directly with inline script
        export BACKUP_FILE_PATH="${BACKUP_DIR}/${COMPRESSED_FILE}"
        python3 << 'PYTHONSCRIPT'
    import os
    import sys
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaFileUpload
    from googleapiclient.errors import HttpError

    CREDENTIALS_FILE = '/tmp/credentials.json'
    BACKUP_FILE = os.environ.get('BACKUP_FILE_PATH')
    FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')

    try:
        print(f"Authenticating with service account...")

        # Check if we should use impersonation
        USER_EMAIL = os.environ.get('GDRIVE_USER_EMAIL')

        credentials = service_account.Credentials.from_service_account_file(
            CREDENTIALS_FILE,
            scopes=['https://www.googleapis.com/auth/drive']
        )

        # If user email provided, use domain-wide delegation
        if USER_EMAIL:
            print(f"Using impersonation for user: {USER_EMAIL}")
            credentials = credentials.with_subject(USER_EMAIL)
        else:
            print("Warning: No GDRIVE_USER_EMAIL set, using Service Account directly")

        service = build('drive', 'v3', credentials=credentials)

        print(f"Using folder ID: {FOLDER_ID}")

        # Test access to the folder
        try:
            folder = service.files().get(fileId=FOLDER_ID, fields='id,name').execute()
            print(f"Folder found: {folder.get('name', 'Unknown')}")
        except HttpError as e:
            if e.resp.status == 404:
                print(f"ERROR: Folder {FOLDER_ID} not found")
                print("Share the folder with: kkal-tracker-backup@budgeter-448210.iam.gserviceaccount.com")
            else:
                print(f"ERROR: {e}")
            sys.exit(1)

        # Upload file
        file_metadata = {
            'name': os.path.basename(BACKUP_FILE),
            'parents': [FOLDER_ID]
        }

        print(f"Uploading {os.path.basename(BACKUP_FILE)}...")
        media = MediaFileUpload(BACKUP_FILE, resumable=True)

        # Try different upload approaches
        try:
            # First try: Upload with supportsAllDrives flag
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id,name,size',
                supportsAllDrives=True
            ).execute()
            print(f"Success! File ID: {file.get('id')}")

        except HttpError as upload_error:
            print(f"Direct upload failed: {upload_error}")

            # Second try: Upload to root and move
            print("Trying alternative: upload to root then move...")
            file_metadata_root = {
                'name': os.path.basename(BACKUP_FILE)
            }

            try:
                file = service.files().create(
                    body=file_metadata_root,
                    media_body=media,
                    fields='id,name'
                ).execute()

                file_id = file.get('id')
                print(f"File uploaded to root: {file_id}")

                # Now move it to the folder
                file = service.files().update(
                    fileId=file_id,
                    addParents=FOLDER_ID,
                    removeParents='root',
                    fields='id,parents'
                ).execute()

                print(f"Moved to folder successfully!")

            except HttpError as e:
                print(f"Alternative approach also failed: {e}")
                raise

    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)
    PYTHONSCRIPT

        # Clean up
        rm -f /tmp/credentials.json
        echo "Upload completed"
    else
        echo "Google Drive credentials or folder ID not found, skipping upload"
    fi

    # Clean up old local backups
    echo "Cleaning up old local backups (keeping last ${RETENTION_DAYS} days)..."
    find "${BACKUP_DIR}" -name "kkal_tracker_backup_*.db.gz" -type f -mtime +${RETENTION_DAYS} -delete

    # List current local backups
    echo "Current local backups in ${BACKUP_DIR}:"
    ls -lh "${BACKUP_DIR}"/kkal_tracker_backup_*.db.gz 2>/dev/null || echo "No backups found"

    echo "Backup process completed successfully"
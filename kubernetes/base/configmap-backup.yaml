apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-script
data:
  backup.sh: |
    #!/bin/bash
    set -e

    # Configuration
    DB_PATH="${DATABASE_PATH:-/data/app.db}"
    BACKUP_DIR="${BACKUP_PATH:-/data/backups}"
    RETENTION_DAYS="${RETENTION_DAYS:-7}"
    GDRIVE_FOLDER_ID="${GDRIVE_FOLDER_ID}"
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    BACKUP_FILE="kkal_tracker_backup_${TIMESTAMP}.db"

    # Create backup directory if it doesn't exist
    mkdir -p "${BACKUP_DIR}"

    # Check if database exists
    if [ ! -f "${DB_PATH}" ]; then
        echo "Error: Database file not found at ${DB_PATH}"
        exit 1
    fi

    echo "Starting backup of database: ${DB_PATH}"
    echo "Backup timestamp: ${TIMESTAMP}"

    # Install required packages
    echo "Installing required packages..."
    apt-get update -qq && apt-get install -qq -y sqlite3 > /dev/null
    pip3 install --quiet google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

    # Create backup using SQLite's backup command (ensures consistency)
    echo "Creating SQLite backup..."
    sqlite3 "${DB_PATH}" ".backup '${BACKUP_DIR}/${BACKUP_FILE}'"

    # Verify backup was created
    if [ ! -f "${BACKUP_DIR}/${BACKUP_FILE}" ]; then
        echo "Error: Backup file was not created"
        exit 1
    fi

    # Get backup size
    BACKUP_SIZE=$(du -h "${BACKUP_DIR}/${BACKUP_FILE}" | cut -f1)
    echo "Backup created successfully: ${BACKUP_FILE} (${BACKUP_SIZE})"

    # Compress backup
    echo "Compressing backup..."
    gzip "${BACKUP_DIR}/${BACKUP_FILE}"
    COMPRESSED_FILE="${BACKUP_FILE}.gz"
    COMPRESSED_SIZE=$(du -h "${BACKUP_DIR}/${COMPRESSED_FILE}" | cut -f1)
    echo "Compressed backup: ${COMPRESSED_FILE} (${COMPRESSED_SIZE})"

    # Upload to Google Drive if credentials are provided
    if [ -n "${GOOGLE_CREDENTIALS_JSON}" ]; then
        echo "Uploading to Google Drive..."

        # Save credentials to file
        echo "${GOOGLE_CREDENTIALS_JSON}" > /tmp/credentials.json

        # Create Python script for upload
        cat > /tmp/upload_to_drive.py << 'PYTHON_EOF'
import os
import sys
import json
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError

# Configuration
CREDENTIALS_FILE = '/tmp/credentials.json'
BACKUP_FILE = sys.argv[1]
FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')

try:
    # Authenticate with more verbose error handling
    print(f"Authenticating with service account...")
    credentials = service_account.Credentials.from_service_account_file(
        CREDENTIALS_FILE,
        scopes=['https://www.googleapis.com/auth/drive']
    )

    service = build('drive', 'v3', credentials=credentials)

    # If folder ID is provided, upload directly there
    if FOLDER_ID:
        print(f"Using folder ID: {FOLDER_ID}")

        # Test access to the folder
        try:
            folder = service.files().get(fileId=FOLDER_ID, fields='id,name,permissions').execute()
            print(f"Folder found: {folder.get('name', 'Unknown')}")

            # Check permissions
            permissions = folder.get('permissions', [])
            print(f"Number of permissions: {len(permissions)}")

        except HttpError as e:
            if e.resp.status == 404:
                print(f"ERROR: Folder with ID {FOLDER_ID} not found or not accessible")
                print("Make sure the folder is shared with: kkal-tracker-backup@budgeter-448210.iam.gserviceaccount.com")
            else:
                print(f"ERROR accessing folder: {e}")
            sys.exit(1)

        # Upload file to the specific folder
        file_metadata = {
            'name': os.path.basename(BACKUP_FILE),
            'parents': [FOLDER_ID]
        }
    else:
        # Create folder structure in root
        print("No folder ID provided, uploading to root")
        file_metadata = {
            'name': os.path.basename(BACKUP_FILE)
        }

    # Upload the file
    print(f"Uploading {os.path.basename(BACKUP_FILE)}...")
    media = MediaFileUpload(BACKUP_FILE, resumable=True)

    file = service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id,name,size'
    ).execute()

    print(f"Successfully uploaded!")
    print(f"  File: {file.get('name')}")
    print(f"  ID: {file.get('id')}")
    print(f"  Size: {file.get('size', 'Unknown')} bytes")

except HttpError as e:
    print(f"HTTP Error: {e}")
    if e.resp.status == 403:
        print("Permission denied. Make sure:")
        print("1. The service account has access to the folder")
        print("2. The folder is shared with: kkal-tracker-backup@budgeter-448210.iam.gserviceaccount.com")
    sys.exit(1)
except Exception as e:
    print(f"Unexpected error: {e}")
    sys.exit(1)
PYTHON_EOF

        # Run upload script
        python3 /tmp/upload_to_drive.py "${BACKUP_DIR}/${COMPRESSED_FILE}"

        # Clean up credentials
        rm -f /tmp/credentials.json /tmp/upload_to_drive.py

        echo "Upload to Google Drive completed"
    else
        echo "Google Drive credentials not found, skipping upload"
    fi

    # Clean up old local backups (keep only last N days)
    echo "Cleaning up old local backups (keeping last ${RETENTION_DAYS} days)..."
    find "${BACKUP_DIR}" -name "kkal_tracker_backup_*.db.gz" -type f -mtime +${RETENTION_DAYS} -delete

    # List current local backups
    echo "Current local backups in ${BACKUP_DIR}:"
    ls -lh "${BACKUP_DIR}"/kkal_tracker_backup_*.db.gz 2>/dev/null || echo "No backups found"

    echo "Backup process completed successfully"